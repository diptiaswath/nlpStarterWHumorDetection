{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models and Vectorization Strategies for Text Classification\n",
    "\n",
    "This try-it focuses on weighing the positives and negatives of different estimators and vectorization strategies for a text classification problem.  In order to consider each of these components, you should make use of the `Pipeline` and `GridSearchCV` objects in scikitlearn to try different combinations of vectorizers with different estimators.  For each of these, you also want to use the `.cv_results_` to examine the time for the estimator to fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The dataset below is from [kaggle]() and contains a dataset named the \"ColBert Dataset\" created for this [paper](https://arxiv.org/pdf/2004.12765.pdf).  You are to use the text column to classify whether or not the text was humorous.  It is loaded and displayed below.\n",
    "\n",
    "**Note:** The original dataset contains 200K rows of data. It is best to try to use the full dtaset. If the original dataset is too large for your computer, please use the 'dataset-minimal.csv', which has been reduced to 100K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import parallel_backend\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# NLTK package with its module imports for tokenizing and normalizing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_data/dataset-minimal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 reasons the 2016 election feels so personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2  What do you call a turtle without its shell? d...   True\n",
       "3      5 reasons the 2016 election feels so personal  False\n",
       "4  Pasco police shot mexican migrant from behind,...  False"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "# Distribution of target \n",
    "###################################################################################################################\n",
    "# Count Plot of target 'humor'\n",
    "df['humor'].value_counts(normalize=True)\n",
    "\n",
    "sns.countplot(x='humor', data=df)\n",
    "plt.title('Count of target \"humor\" ')\n",
    "plt.show()\n",
    "\n",
    "## Conclusion: Well-balanced data set with equal positive (humor=true) and negative classes (humor=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (99999, 1)\n",
      "Shape of y: (99999,)\n",
      "X_train shape: (74999,)\n",
      "X_test shape: (25000,)\n",
      "y_train shape: (74999,)\n",
      "y_test shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "# Train and Test split (75/25) before pre-processing text \n",
    "###################################################################################################################\n",
    "X = df.drop('humor', axis = 1)\n",
    "y = df['humor']\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['text'], y,\n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=243824)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "\n",
    "\n",
    "**Text preprocessing:** As a pre-processing step, perform both `stemming` and `lemmatizing` to normalize your text before classifying. For each technique use both the `CountVectorize`r and `TfidifVectorizer` and use options for stop words and max features to prepare the text data for your estimator.\n",
    "\n",
    "**Classification:** Once you have prepared the text data with stemming lemmatizing techniques, consider `LogisticRegression`, `DecisionTreeClassifier`, and `MultinomialNB` as classification algorithms for the data. Compare their performance in terms of accuracy and speed.\n",
    "\n",
    "Share the results of your best classifier in the form of a table with the best version of each estimator, a dictionary of the best parameters and the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed train data sample ['proctologist work part time kfc .... still finger lick good ?', 'hear gangster panda ? eat shoot leav .', 'new tax plan : make america great sinc 1980', \"'ve warn whoever stole broken bathroom scale . wo n't get weigh !\", 'count dooku alway puzzl wife , sue .']\n",
      "\n",
      "\n",
      "Lemmatized train data sample ['proctologist work part time kfc .... still finger licking good ?', 'hear gangster panda ? eats shoot leaf .', 'new tax plan : making america great since 1980', \"'ve warned whoever stole broken bathroom scale . wo n't get weigh !\", 'count dooku always puzzled wife , sue .']\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################\n",
    "# Data Preprocessing and Normalization - tokenization with stemming or lemmatizer on lower case tokens \n",
    "# with stop word removal\n",
    "###########################################################################################################\n",
    "\n",
    "# Custom Transformer for Stemming\n",
    "class StemmerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [' '.join([self.stemmer.stem(token) for token in word_tokenize(text.lower()) if token not in self.stop_words]) for text in X]\n",
    "\n",
    "# Custom Transformer for Lemmatization\n",
    "class LemmatizerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lemma = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [' '.join([self.lemma.lemmatize(token) for token in word_tokenize(text.lower()) if token not in self.stop_words]) for text in X]\n",
    "\n",
    "    \n",
    "# Test tokenization with stemmer \n",
    "stemmer = StemmerTransformer()\n",
    "X_stransformed = stemmer.fit_transform(X_train)\n",
    "print(\"Stemmed train data sample\", X_stransformed[:5])\n",
    "\n",
    "# Test tokenization with lemmatizer\n",
    "lemmatizer = LemmatizerTransformer()\n",
    "X_ltransformed = lemmatizer.fit_transform(X_train)\n",
    "print(\"\\n\")\n",
    "print(\"Lemmatized train data sample\", X_ltransformed[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "# 1. Create a Pipeline with the given preprocessor (Porter Stemmer or WordNetLemmatizer), a given vectorizer \n",
    "# (CountVectorizer or TfIdfVectorizer) and a given classifier (NaiveBayes or DecisionTree or LogistricRegression)\n",
    "# 2. Create a GridSearchCV instance with this Pipeline\n",
    "# 3. Return GridSearchCVInstance\n",
    "###################################################################################################################\n",
    "def create_nlp_pipeline(preprocessor='stemmer', vectorizer='count', classifier='naive_bayes', param_grid=None):\n",
    "    # Set up preprocessor \n",
    "    if preprocessor == 'stemmer':\n",
    "        preprocessor_step = ('preprocessor', StemmerTransformer())\n",
    "    elif preprocessor == 'lemmatizer':\n",
    "        preprocessor_step = ('preprocessor', LemmatizerTransformer())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid preprocessor. Choose 'stemmer' or 'lemmatizer'.\")\n",
    "\n",
    "    # Set up vectorizer\n",
    "    if vectorizer == 'count':\n",
    "        vectorizer_step = ('vectorizer', CountVectorizer())\n",
    "    elif vectorizer == 'tfidf':\n",
    "        vectorizer_step = ('vectorizer', TfidfVectorizer())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid vectorizer. Choose 'count' or 'tfidf'.\")\n",
    "\n",
    "    # Set up classifier\n",
    "    if classifier == 'naive_bayes':\n",
    "        classifier_step = ('classifier', MultinomialNB())\n",
    "    elif classifier == 'logistic_regression':\n",
    "        classifier_step = ('classifier', LogisticRegression())\n",
    "    elif classifier == 'decision_tree':\n",
    "        classifier_step = ('classifier', DecisionTreeClassifier())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid classifier. Choose 'naive_bayes', 'logistic_regression', or 'decision_tree'.\")\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        preprocessor_step,\n",
    "        vectorizer_step,\n",
    "        classifier_step\n",
    "    ])\n",
    "\n",
    "    # Set up default param_grid if not provided\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'vectorizer__max_df'       : [0.5, 1.0],\n",
    "            'vectorizer__ngram_range'  : [(1, 1), (1, 2)],\n",
    "            'vectorizer__max_features' : [1000, 2000],\n",
    "        }\n",
    "        if classifier == 'naive_bayes':\n",
    "            param_grid['classifier__alpha'] = [0.1, 0.5, 1.0]\n",
    "        elif classifier == 'logistic_regression':\n",
    "            param_grid['classifier__C'] = [0.1, 1.0, 10.0]\n",
    "        elif classifier == 'decision_tree':\n",
    "            param_grid['classifier__max_depth'] = [None, 10, 20]\n",
    "\n",
    "    # Instantiate GridSearchCV \n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1)\n",
    "    return grid_search\n",
    "\n",
    "###################################################################################################################\n",
    "# Fit and Evaluate the classifier models with GridSearch\n",
    "# Return results as a dict\n",
    "###################################################################################################################\n",
    "def fit_evaluate_model(grid_search, X_train, y_train, X_test, y_test):\n",
    "    try:\n",
    "        with parallel_backend('loky'):\n",
    "            grid_search.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"Parallel processing failed with error: {e}\")\n",
    "        print(\"Falling back to single-core processing...\")\n",
    "        grid_search.n_jobs = 1\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Use best model to make predictions\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Get best parameters, best score, best estimator, index of best parameters, best fit time\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_index = grid_search.best_index_\n",
    "    best_fit_time = grid_search.cv_results_['mean_fit_time'][best_index]\n",
    "\n",
    "    # Get test accuracy score \n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Make results dictionary\n",
    "    results = {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_params\": best_params,\n",
    "        \"best_cv_score\": best_score,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"best_fit_time\": best_fit_time,\n",
    "        \"predictions\": y_pred\n",
    "    }\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Cross-Validation Accuracy Score:\", best_score)\n",
    "    print(\"Test Accuracy Score:\", test_accuracy)\n",
    "    print(\"Mean Fit Time:\", best_fit_time)\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Naive Bayes Classifier with Stemmer and CountVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x31f8647d0 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'WordListCorpusReader' object has no attribute '_unload'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/_base.py\", line 26, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 385, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 834, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 556, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/reusable_executor.py\", line 176, in submit\n",
      "    return super().submit(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 1129, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "# Naive Bayes Classifier Runs1 and 2 - with Stemmer and CountVectorizer, with Lemmatizer and TfIdfVectorizer\n",
    "###################################################################################################################\n",
    "\n",
    "# Create pipeline with stemmer, CountVectorizer, and Naive Bayes followed by model evaluation\n",
    "print(\"\\nEvaluating Naive Bayes Classifier with Stemmer and CountVectorizer\")\n",
    "grid_search_nb = create_nlp_pipeline(preprocessor='stemmer', vectorizer='count', classifier='naive_bayes')\n",
    "results_nb_stemmer_countvect = fit_evaluate_model(grid_search_nb, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Create pipeline with lemmatizer, CountVectorizer, and Naive Bayes followed by model evaluation\n",
    "print(\"\\nEvaluating Naive Bayes Classifier with Lemmatizer and TfIdfVectorizer\")\n",
    "grid_search_nb2 = create_nlp_pipeline(preprocessor='lemmatizer', vectorizer='tfidf', classifier='naive_bayes')\n",
    "results_nb_lemmatizer_tfidfvect = fit_evaluate_model(grid_search_nb2, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "# Naive Bayes Classifier Runs3 and 4 - with Stemmer and TfIdfVectorizer, with Lemmatizer and CountVectorizer\n",
    "###################################################################################################################\n",
    "# Create pipeline with stemmer, CountVectorizer, and Naive Bayes followed by model evaluation\n",
    "print(\"\\nEvaluating Naive Bayes Classifier with Stemmer and TfIdfVectorizer\")\n",
    "grid_search_nb3 = create_nlp_pipeline(preprocessor='stemmer', vectorizer='tfidf', classifier='naive_bayes')\n",
    "results_nb_stemmer_tfidfvect = fit_evaluate_model(grid_search_nb3, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Create pipeline with lemmatizer, CountVectorizer, and Naive Bayes followed by model evaluation\n",
    "print(\"\\nEvaluating Naive Bayes Classifier with Lemmatizer and CountVectorizer\")\n",
    "grid_search_nb4 = create_nlp_pipeline(preprocessor='lemmatizer', vectorizer='count', classifier='naive_bayes')\n",
    "results_nb_lemmatizer_countvect = fit_evaluate_model(grid_search_nb4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LGR Classifier with Stemmer and CountVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__C': 1.0, 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best Cross-Validation Accuracy Score: 0.8597714860990733\n",
      "Test Accuracy Score: 0.85888\n",
      "Mean Fit Time: 6.21576247215271\n",
      "\n",
      "Evaluating LGR Classifier with Lemmatizer and TfIdfVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__C': 1.0, 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 1)}\n",
      "Best Cross-Validation Accuracy Score: 0.8602914923217103\n",
      "Test Accuracy Score: 0.85824\n",
      "Mean Fit Time: 3.4539157867431642\n",
      "\n",
      "Evaluating LGR Classifier with Stemmer and TfIdfVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x348d47f90 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'WordListCorpusReader' object has no attribute '_unload'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/_base.py\", line 26, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 385, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 834, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 556, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/reusable_executor.py\", line 176, in submit\n",
      "    return super().submit(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 1129, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__C': 10.0, 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best Cross-Validation Accuracy Score: 0.8602914780985399\n",
      "Test Accuracy Score: 0.86008\n",
      "Mean Fit Time: 6.193637990951538\n",
      "\n",
      "Evaluating LGR Classifier with Lemmatizer and CountVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x3203bfa50 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'WordListCorpusReader' object has no attribute '_unload'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/_base.py\", line 26, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 385, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 834, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 556, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/reusable_executor.py\", line 176, in submit\n",
      "    return super().submit(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 1129, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__C': 1.0, 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best Cross-Validation Accuracy Score: 0.8603848123208214\n",
      "Test Accuracy Score: 0.85916\n",
      "Mean Fit Time: 4.010002183914184\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "# Logistic Regression Runs1 and 2 - with Stemmer and CountVectorizer, with Lemmatizer and TfIdfVectorizer\n",
    "###################################################################################################################\n",
    "# Create pipeline with stemmer, CountVectorizer, and lgr followed by model evaluation\n",
    "print(\"\\nEvaluating LGR Classifier with Stemmer and CountVectorizer\")\n",
    "grid_search_lgr = create_nlp_pipeline(preprocessor='stemmer', vectorizer='count', classifier='logistic_regression')\n",
    "results_lgr_stemmer_countvect = fit_evaluate_model(grid_search_lgr, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Create pipeline with lemmatizer, CountVectorizer, and lgr followed by model evaluation\n",
    "print(\"\\nEvaluating LGR Classifier with Lemmatizer and TfIdfVectorizer\")\n",
    "grid_search_lgr2 = create_nlp_pipeline(preprocessor='lemmatizer', vectorizer='tfidf', classifier='logistic_regression')\n",
    "results_lgr_lemmatizer_tfidfvect = fit_evaluate_model(grid_search_lgr2, X_train, y_train, X_test, y_test)\n",
    "\n",
    "###################################################################################################################\n",
    "# Logistic Regression Runs3 and 4 - with Stemmer and TfIdfVectorizer, with Lemmatizer and CountVectorizer\n",
    "###################################################################################################################\n",
    "# Create pipeline with stemmer, CountVectorizer, and LGR followed by model evaluation\n",
    "print(\"\\nEvaluating LGR Classifier with Stemmer and TfIdfVectorizer\")\n",
    "grid_search_lgr3 = create_nlp_pipeline(preprocessor='stemmer', vectorizer='tfidf', classifier='logistic_regression')\n",
    "results_lgr_stemmer_tfidfvect = fit_evaluate_model(grid_search_lgr3, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Create pipeline with lemmatizer, CountVectorizer, and LGR followed by model evaluation\n",
    "print(\"\\nEvaluating LGR Classifier with Lemmatizer and CountVectorizer\")\n",
    "grid_search_lgr4 = create_nlp_pipeline(preprocessor='lemmatizer', vectorizer='count', classifier='logistic_regression')\n",
    "results_lgr_lemmatizer_countvect = fit_evaluate_model(grid_search_lgr4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Decision Tree Classifier with Stemmer and CountVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x32ed98410 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'WordListCorpusReader' object has no attribute '_unload'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/_base.py\", line 26, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 385, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 834, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 556, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/reusable_executor.py\", line 176, in submit\n",
      "    return super().submit(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 1129, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__max_depth': 7, 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 1)}\n",
      "Best Cross-Validation Accuracy Score: 0.6029280280907615\n",
      "Test Accuracy Score: 0.59912\n",
      "Mean Fit Time: 5.517806529998779\n",
      "\n",
      "Evaluating Decision Tree Classifier with Lemmatizer and TfIdfVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__max_depth': 7, 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 500, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best Cross-Validation Accuracy Score: 0.5911012600840057\n",
      "Test Accuracy Score: 0.59136\n",
      "Mean Fit Time: 3.8591135025024412\n",
      "\n",
      "Evaluating Decision Tree Classifier with Stemmer and TfIdfVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__max_depth': 7, 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 1000, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best Cross-Validation Accuracy Score: 0.6028613640909394\n",
      "Test Accuracy Score: 0.59932\n",
      "Mean Fit Time: 6.089656019210816\n",
      "\n",
      "Evaluating Decision Tree Classifier with Lemmatizer and CountVectorizer\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x35becf1d0 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'WordListCorpusReader' object has no attribute '_unload'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/_base.py\", line 26, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 385, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 834, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 556, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/reusable_executor.py\", line 176, in submit\n",
      "    return super().submit(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 1129, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel processing failed with error: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'classifier__max_depth': 7, 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 500, 'vectorizer__ngram_range': (1, 1)}\n",
      "Best Cross-Validation Accuracy Score: 0.5911812671955909\n",
      "Test Accuracy Score: 0.5912\n",
      "Mean Fit Time: 3.2768614292144775\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "# DecisionTree Runs1 and 2 - with Stemmer and CountVectorizer, with Lemmatizer and TfIdfVectorizer\n",
    "###################################################################################################################\n",
    "# Create pipeline with stemmer, CountVectorizer, and DecisionTree followed by model evaluation\n",
    "print(\"\\nEvaluating Decision Tree Classifier with Stemmer and CountVectorizer\")\n",
    "grid_search_dc = create_nlp_pipeline(preprocessor='stemmer', vectorizer='count', classifier='decision_tree')\n",
    "results_dc_stemmer_countvect = fit_evaluate_model(grid_search_dc, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Create pipeline with lemmatizer, CountVectorizer, and DC followed by model evaluation\n",
    "print(\"\\nEvaluating Decision Tree Classifier with Lemmatizer and TfIdfVectorizer\")\n",
    "grid_search_dc2 = create_nlp_pipeline(preprocessor='lemmatizer', vectorizer='tfidf', classifier='decision_tree')\n",
    "results_dc_lemmatizer_tfidfvect = fit_evaluate_model(grid_search_dc2, X_train, y_train, X_test, y_test)\n",
    "\n",
    "###################################################################################################################\n",
    "# DecisionTree Runs3 and 4 - with Stemmer and TfIdfVectorizer, with Lemmatizer and CountVectorizer\n",
    "###################################################################################################################\n",
    "# Create pipeline with stemmer, CountVectorizer, and DC followed by model evaluation\n",
    "print(\"\\nEvaluating Decision Tree Classifier with Stemmer and TfIdfVectorizer\")\n",
    "grid_search_dc3 = create_nlp_pipeline(preprocessor='stemmer', vectorizer='tfidf', classifier='decision_tree')\n",
    "results_dc_stemmer_tfidfvect = fit_evaluate_model(grid_search_dc3, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Create pipeline with lemmatizer, CountVectorizer, and DC followed by model evaluation\n",
    "print(\"\\nEvaluating Decision Tree Classifier with Lemmatizer and CountVectorizer\")\n",
    "grid_search_dc4 = create_nlp_pipeline(preprocessor='lemmatizer', vectorizer='count', classifier='decision_tree')\n",
    "results_dc_lemmatizer_countvect = fit_evaluate_model(grid_search_dc4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel processing failed with error: name 'parallel_backend' is not defined\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Parallel processing failed with error: name 'parallel_backend' is not defined\n",
      "Falling back to single-core processing...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best parameters: {'classifier__alpha': 0.5, 'vectorizer__max_df': 0.5, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best cross-validation score: 0.9002653501344534\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('stemmer', Stemmer()),\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "#pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "#predictions = pipeline.predict(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer__max_df': [0.5, 0.75, 1.0],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'classifier__alpha': [0.1, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1)\n",
    "\n",
    "# Fit on training data (X_train, y_train)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Use best model to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Get the best parameters, best score, best estimator, index of best parameters, best fit time\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_index = grid_search.best_index_\n",
    "best_fit_time = grid_search.cv_results_['mean_fit_time'][best_index]\n",
    "\n",
    "# Get test accuracy score \n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "#classification_report = metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Accuracy Score:\", best_score)\n",
    "print(\"Test Accuracy Score:\", test_accuracy)\n",
    "print(\"Mean Fit Time:\", best_fit_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# Results: Plot all fit times (aka training times) across the varied combinations for measure of speed\n",
    "###########################################################################################################\n",
    "\n",
    "def plot_best_fit_times(results_dict):\n",
    "    # Extract best_fit_times\n",
    "    names = list(results_dict.keys())\n",
    "    times = [results_dict[name]['best_fit_time'] for name in names]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    # Create bar plot\n",
    "    bars = ax.bar(names, times)\n",
    "\n",
    "    ax.set_ylabel('Best Fit Time (seconds)')\n",
    "    ax.set_title('Best Fit Time for Different NLP Pipeline Configurations')\n",
    "    ax.set_xticks(range(len(names)))\n",
    "    ax.set_xticklabels(names, rotation=90, ha='right')\n",
    "\n",
    "    # Add value labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# All results dictionary \n",
    "all_results = {\n",
    "    'NB Stemmer CountVect': results_nb_stemmer_countvect,\n",
    "    'NB Lemmatizer TfidfVect': results_nb_lemmatizer_tfidfvect,\n",
    "    'NB Stemmer TfidfVect': results_nb_stemmer_tfidfvect,\n",
    "    'NB Lemmatizer CountVect': results_nb_lemmatizer_countvect,\n",
    "    'LGR Stemmer CountVect': results_lgr_stemmer_countvect,\n",
    "    'LGR Lemmatizer TfidfVect': results_lgr_lemmatizer_tfidfvect,\n",
    "    'LGR Stemmer TfidfVect': results_lgr_stemmer_tfidfvect,\n",
    "    'LGR Lemmatizer CountVect': results_lgr_lemmatizer_countvect,\n",
    "    'DC Stemmer CountVect': results_dc_stemmer_countvect,\n",
    "    'DC Lemmatizer TfidfVect': results_dc_lemmatizer_tfidfvect,\n",
    "    'DC Stemmer TfidfVect': results_dc_stemmer_tfidfvect,\n",
    "    'DC Lemmatizer CountVect': results_dc_lemmatizer_countvect\n",
    "}\n",
    "\n",
    "# Plot best fit times \n",
    "plot_best_fit_times(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# Results: Plot all NLP model accuracy scores across the varied combinations of preprocessor and vectorizer \n",
    "# for measure of performance\n",
    "###########################################################################################################\n",
    "\n",
    "def plot_test_accuracy_scores(results_dict):\n",
    "    # Extract test accuracy scores\n",
    "    names = list(results_dict.keys())\n",
    "    scores = [results_dict[name]['test_accuracy'] for name in names]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    # Create bar plot\n",
    "    bars = ax.bar(names, scores)\n",
    "\n",
    "    ax.set_ylabel('Test Accuracy Score')\n",
    "    ax.set_title('Test Accuracy Scores for Different NLP Pipeline Configurations')\n",
    "    ax.set_xticks(range(len(names)))\n",
    "    ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "    ax.set_ylim(0, 1)   # accuracy scores between 0 and 1\n",
    "\n",
    "    # Add value labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# All results dictionary\n",
    "all_results = {\n",
    "    'NB Stemmer CountVect': results_nb_stemmer_countvect,\n",
    "    'NB Lemmatizer TfidfVect': results_nb_lemmatizer_tfidfvect,\n",
    "    'NB Stemmer TfidfVect': results_nb_stemmer_tfidfvect,\n",
    "    'NB Lemmatizer CountVect': results_nb_lemmatizer_countvect,\n",
    "    'LGR Stemmer CountVect': results_lgr_stemmer_countvect,\n",
    "    'LGR Lemmatizer TfidfVect': results_lgr_lemmatizer_tfidfvect,\n",
    "    'LGR Stemmer TfidfVect': results_lgr_stemmer_tfidfvect,\n",
    "    'LGR Lemmatizer CountVect': results_lgr_lemmatizer_countvect,\n",
    "    'DC Stemmer CountVect': results_dc_stemmer_countvect,\n",
    "    'DC Lemmatizer TfidfVect': results_dc_lemmatizer_tfidfvect,\n",
    "    'DC Stemmer TfidfVect': results_dc_stemmer_tfidfvect,\n",
    "    'DC Lemmatizer CountVect': results_dc_lemmatizer_countvect\n",
    "}\n",
    "\n",
    "# Plot Test Accuracy Scores \n",
    "plot_test_accuracy_scores(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# Results: Capture all NLP processing results from the varied combinations of preprocessor and vectorizer  \n",
    "# with its classification model configuration into a pandas dataframe and write to csv\n",
    "###########################################################################################################\n",
    "\n",
    "def create_results_dataframe(results_dict):\n",
    "    model_configs = []\n",
    "    best_params = []\n",
    "    best_cv_scores = []\n",
    "    test_accuracies = []\n",
    "    best_fit_times = []\n",
    "\n",
    "    # Extract data from each result dictionary\n",
    "    for config, result in results_dict.items():\n",
    "        model_configs.append(config)\n",
    "        best_params.append(str(result['best_params']))  # Convert dict to string\n",
    "        best_cv_scores.append(result['best_cv_score'])\n",
    "        test_accuracies.append(result['test_accuracy'])\n",
    "        best_fit_times.append(result['best_fit_time'])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Model Config'   : model_configs,\n",
    "        'Best Parameters': best_params,\n",
    "        'Best CV Score': best_cv_scores,\n",
    "        'Test Accuracy': test_accuracies,\n",
    "        'Best Fit Time': best_fit_times\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# All results dictionary for each model configuration\n",
    "all_results = {\n",
    "    'NB Stemmer CountVect': results_nb_stemmer_countvect,\n",
    "    'NB Lemmatizer TfidfVect': results_nb_lemmatizer_tfidfvect,\n",
    "    'NB Stemmer TfidfVect': results_nb_stemmer_tfidfvect,\n",
    "    'NB Lemmatizer CountVect': results_nb_lemmatizer_countvect,\n",
    "    'LGR Stemmer CountVect': results_lgr_stemmer_countvect,\n",
    "    'LGR Lemmatizer TfidfVect': results_lgr_lemmatizer_tfidfvect,\n",
    "    'LGR Stemmer TfidfVect': results_lgr_stemmer_tfidfvect,\n",
    "    'LGR Lemmatizer CountVect': results_lgr_lemmatizer_countvect,\n",
    "    'DC Stemmer CountVect': results_dc_stemmer_countvect,\n",
    "    'DC Lemmatizer TfidfVect': results_dc_lemmatizer_tfidfvect,\n",
    "    'DC Stemmer TfidfVect': results_dc_stemmer_tfidfvect,\n",
    "    'DC Lemmatizer CountVect': results_dc_lemmatizer_countvect\n",
    "}\n",
    "\n",
    "# Create a dataframe\n",
    "results_df = create_results_dataframe(all_results)\n",
    "\n",
    "# Display \n",
    "print(results_df)\n",
    "\n",
    "# Write to CSV\n",
    "csv_filename = 'nlp_pipeline_results.csv'\n",
    "results_df.to_csv(csv_filename, index=False)\n",
    "print(f\"Results have been written to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayes</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              best_params best_score\n",
       "model                               \n",
       "Logistic                            \n",
       "Decision Tree                       \n",
       "Bayes                               "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guideline has been adopted (see above) to plot and capture the results across all model configurations\n",
    "pd.DataFrame({'model': ['Logistic', 'Decision Tree', 'Bayes'], \n",
    "             'best_params': ['', '', ''],\n",
    "             'best_score': ['', '', '']}).set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
